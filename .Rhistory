parques_sf <- osmdata_sf(parques)
parques_geometria <- parques_sf$osm_polygons |>
dplyr::select(osm_id, name)
parques_geometria <- st_as_sf(parques_sf$osm_polygons)
centroides <- st_centroid(parques_geometria, byid = TRUE)
centroides <- centroides |>
mutate(x=st_coordinates(centroides)[, "X"]) |>
mutate(y=st_coordinates(centroides)[, "Y"])
leaflet() |>
addTiles() |>
setView(lng = longitud_central, lat = latitud_central, zoom = 12) |>
addPolygons(data = parques_geometria, col = "red",weight = 10,
opacity = 0.8, popup = parques_geometria$name) |>
addCircles(lng = centroides$x,
lat = centroides$y,
col = "darkblue", opacity = 0.5, radius = 1)
centroides_sf <- st_as_sf(centroides, coords = c("x", "y"), crs=4326)
sf_db <- st_as_sf(db, coords = c("lon", "lat"),  crs = 4326)
View(centroides)
# ¡ADVERTENCIA! Esto va a ser demorado...
dist_matrix <- st_distance(x = sf_db, y = centroides_sf)
dim(dist_matrix)
dist_min <- apply(dist_matrix, 1, min)
db <- db |> mutate(distancia_parque = dist_min)
# Calculamos el ancho de banda mediante la regla de Scott.
num_binwidth <- 3.5 * sd(db$distancia_parque, na.rm = TRUE) / length(db$distancia_parque[!is.na(db$distancia_parque)])^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)
db |>
ggplot(aes(x = distancia_parque)) +
geom_histogram(mapping = aes(y = (after_stat(count))/sum(after_stat(count))),
color ="#FFFFFF", fill= "#3a5e8cFF", show.legend = FALSE, na.rm = TRUE,
binwidth = num_binwidth, linewidth = 0.2, alpha = 0.8, closed = 'left') +
scale_y_continuous(expand = expansion(mult = c(0, 0.05)),
labels = scales::label_number(scale = 100)) +
scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
labs(x = "Distancia al parque más cercano", y = "Porcentaje de observaciones (%)") +
theme_classic()
install.packages("keras")
library(reticulate)
reticulate::virtualenv_create("r-reticulate", python = install_python())
library(keras)
install_keras(envname = "r-reticulate")
install.packages("keras")
library(reticulate)
reticulate::virtualenv_create("r-reticulate", python = install_python())
library(keras)
install_keras(envname = "r-reticulate")
install.packages("keras")
library(reticulate)
reticulate::virtualenv_create("r-reticulate", python = install_python())
library(keras)
install_keras(envname = "r-reticulate")
install.packages("keras")
library(reticulate)
reticulate::virtualenv_create("r-reticulate", python = install_python())
library(keras)
install_keras(envname = "r-reticulate")
# === Establecer el directorio de trabajo ===
setwd(dirname(dirname(rstudioapi::getActiveDocumentContext()$path)))
## 0) Paquetes y opciones generales -------------------------------------------
if (!requireNamespace("pacman", quietly = TRUE)) {
install.packages("pacman")
}
pacman::p_load(
tidyverse,
stringi,
rio,
leaflet,
here,
osmdata,
sf,
lwgeom,
doParallel,
foreach,
httr2,
curl
)
# Se desactiva s2 para evitar problemas en joins espaciales
sf::sf_use_s2(FALSE)
#### ============================================================
### 1) Funciones auxiliares
#### ============================================================
## 1.1) Función para extraer datos desde OpenStreetMap -------------------------
obtener_osmdata <- function(llave, valor, tipo_dato) {
# Se arma la consulta para el bounding box de Bogotá
consulta_osm <- osmdata::opq(bbox = osmdata::getbb("Bogotá Colombia")) |>
osmdata::add_osm_feature(key = llave, value = valor)
# Se descarga el objeto completo en formato sf
objeto_sf <- osmdata::osmdata_sf(consulta_osm)
# Según el tipo de geometría, se escoge la capa correspondiente
sf_filtrado <- dplyr::case_when(
tipo_dato == "linea"   ~ objeto_sf$osm_lines,
tipo_dato == "puntos"  ~ objeto_sf$osm_points,
tipo_dato == "poligono" ~ objeto_sf$osm_polygons,
TRUE                   ~ stop("tipo_dato debe ser 'linea', 'puntos' o 'poligono'")
) |>
dplyr::select(osm_id, name) |>
sf::st_as_sf(crs = 4326) |>
sf::st_transform(crs = 4326) |>
sf::st_make_valid()
return(sf_filtrado)
}
distneastfeat <- function(data_original, data_feat, n_variable, tipo_dato) {
# Si los features son polígonos, se trabaja con sus centroides
if (identical(tipo_dato, "poligono")) {
data_feat <- sf::st_centroid(data_feat, byid = TRUE)
}
# Matriz de distancias entre cada punto de data_original y cada feature
matriz_dist <- sf::st_distance(x = data_original, y = data_feat)
# Se toma la distancia mínima por observación
dist_min   <- apply(matriz_dist, 1L, min)
data_original[[n_variable]] <- dist_min
return(data_original)
}
## 1.3) Distancia mínima punto-a-conjunto (loop fila a fila) -------------------
distminpoints <- function(data_original, ext_points) {
n_obs   <- nrow(data_original)
dist_min <- vector(mode = "numeric", length = n_obs)
for (i in seq_len(n_obs)) {
dist_vec    <- sf::st_distance(data_original[i, ], ext_points)
dist_min[i] <- min(dist_vec)
}
return(dist_min)
}
train_texto <- readRDS("~/PEG-1/Big Data/taller_3/PS3_Equipo3/stores/train_texto.rds")
test_texto <- readRDS("~/PEG-1/Big Data/taller_3/PS3_Equipo3/stores/test_texto.rds")
View(test_texto)
View(train_texto)
rm(list=())
rm(list = ())
rm(list=ls())
setwd(choose.dir())
library(pacman)
p_load(rio,       # Import/export data.
tidyverse, # Tidy-data.
caret,     # For predictive model assessment.
leaps)     # For subset  model selection
train <- read_csv("stores/train_final.csv")
test  <- read_csv("stores/test_final.csv")
View(train)
train <- train %>% tidyr::drop_na()
test <- test %>% tidyr::drop_na()
train <- read_csv("stores/train_final.csv")
test  <- read_csv("stores/test_final.csv")
_na()
train <- train %>% tidyr::drop_na()
train <- read_csv("stores/train_final.csv")
vars <- c("property_type", "LocNombre", "SCANOMBRE" "CODIGO_UPZ")
vars <- c("property_type", "LocNombre", "SCANOMBRE" "CODIGO_UPZ")
vars <- c("property_type", "LocNombre", "SCANOMBRE", "CODIGO_UPZ")
train[vars] <- lapply(train[vars], as.factor)
test[vars] <- lapply(test[vars], as.factor)
ctrl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE
)
View(test)
train$...1 <- NULL
test$...1 <- NULL
View(train)
ctrl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE
)
set.seed(1234)
model1 <- train(
log(price) ~ . - property_id - city - month -  year - NOMBRE_UPZ,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
train <- train %>% tidyr::drop_na()
train <- read_csv("stores/train_final.csv")
train <- train %>% tidyr::drop_na()
ctrl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE
)
set.seed(1234)
model1 <- train(
log(price) ~ . - property_id - city - month -  year - NOMBRE_UPZ,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
View(train)
vars <- c("property_type", "LocNombre", "SCANOMBRE", "CODIGO_UPZ")
train[vars] <- lapply(train[vars], as.factor)
train$...1 <- NULL
ctrl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE
)
set.seed(1234)
model1 <- train(
log(price) ~ . - property_id - city - month -  year - NOMBRE_UPZ,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
sapply(train, function(x) {
if (is.factor(x)) nlevels(x) else NA
})
train <- train |>
mutate(across(
where(~ is.numeric(.x) && all(.x %in% c(0,1))),
~ factor(.x)
))
test <- test |>
mutate(across(
where(~ is.numeric(.x) && all(.x %in% c(0,1))),
~ factor(.x)
))
#Por validación cruzada estándar
ctrl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE
)
set.seed(1234)
model1 <- train(
log(price) ~ . - property_id - city - month -  year - NOMBRE_UPZ,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
sapply(train, function(x) {
if (is.factor(x)) nlevels(x) else NA
})
train |>
summarise(across(everything(), ~ dplyr::n_distinct(.x))) |>
t()
train <- train |>
select(where(~ n_distinct(.x) > 1))
View(ctrl)
View(test)
set.seed(1234)
model1 <- train(
log(price) ~ . - property_id - city - month -  year - NOMBRE_UPZ,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
set.seed(1234)
model1 <- train(
log(price) ~ . - property_id - month -  year - NOMBRE_UPZ,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
model1
predictSample <- test |>
mutate(
log_price_hat = predict(model1, newdata = test),
price_hat     = exp(log_price_hat)
) |>
select(property_id, price_hat)
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat     = exp(log_price_hat)) |>
select(property_id, price_hat)
View(test)
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
predictSample <- test |>
mutate(log_price_hat = predict(model1, dplyr::select(., -property_id)),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
test_no_id <- test |> select(-property_id)
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = dplyr::select(., -property_id)),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test_no_id),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
View(model1)
espec_modelo <- log(price) ~ . - property_id - month - year - NOMBRE_UPZ
set.seed(1234)
model1 <- train(
espec_modelo,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
ctrl <- trainControl(
method = "cv",
number = 5,
savePredictions = TRUE
)
set.seed(1234)
model1 <- train(
espec_modelo,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
model1
View(ctrl)
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
names(train)
espec_modelo <- log(price) ~ cocina_americana + cocina_integral + gimnasio +
balcon + chimenea + terraza + ascensor + sauna + jacuzzi + piscina + deposito +
walking_closet + duplex + zona_verde + bbq + conjunto_residencial + altillo +
vigilancia_24h + porteria + cctv + parqueadero_cubierto + parqueadero_comunal +
zona_infantil + salon_comunal + zona_humeda + terraza_comunal + pet_friendly +
remodelado + piso_madera + piso_porcelanato + n_parqueaderos + banios + area +
habitaciones + LocNombre + SCANOMBRE + EPE + EPT + EPCC + EPE_UPZ + CODIGO_UPZ +
luminarias + distnearestlibrary + distnearestschool + distnearestmuseum +
distnearesttransmi + recaudo_predial + lon + lat
set.seed(1234)
model1 <- train(
espec_modelo,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
model1
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
espec_modelo <- log(price) ~ property_type + cocina_americana + cocina_integral + gimnasio +
balcon + chimenea + terraza + ascensor + sauna + jacuzzi + piscina + deposito +
walking_closet + duplex + zona_verde + bbq + conjunto_residencial + altillo +
vigilancia_24h + porteria + cctv + parqueadero_cubierto + parqueadero_comunal +
zona_infantil + salon_comunal + zona_humeda + terraza_comunal + pet_friendly +
remodelado + piso_madera + piso_porcelanato + n_parqueaderos + banios + area +
habitaciones + LocNombre + EPE + EPT + EPCC + EPE_UPZ + CODIGO_UPZ +
luminarias + distnearestlibrary + distnearestschool + distnearestmuseum +
distnearesttransmi + recaudo_predial + lon + lat
set.seed(1234)
model1 <- train(
espec_modelo,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
model1
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
model1[["terms"]]
nrow(test)
length(predict(model1, newdata = test))
colSums(is.na(test))
test <- test %>%
mutate(
area = ifelse(is.na(area), median(area, na.rm = TRUE), area)
)
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
espec_modelo <- log(price) ~ property_type + cocina_americana + cocina_integral + gimnasio +
balcon + chimenea + terraza + ascensor + sauna + jacuzzi + piscina + deposito +
walking_closet + duplex + zona_verde + bbq + conjunto_residencial + altillo +
vigilancia_24h + porteria + cctv + parqueadero_cubierto + parqueadero_comunal +
zona_infantil + salon_comunal + zona_humeda + terraza_comunal + pet_friendly +
remodelado + piso_madera + piso_porcelanato + n_parqueaderos + banios + area +
habitaciones + LocNombre + EPE + EPT + EPCC + distnearestlibrary + distnearestschool + distnearestmuseum +
distnearesttransmi + recaudo_predial + lon + lat
set.seed(1234)
model1 <- train(
espec_modelo,
data = train,
metric = "MAE",
method = "glmnet",
trControl = ctrl,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
model1
predictSample <- test |>
mutate(log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat)) |>
select(property_id, price_hat)
head(predictSample)
predictSample <- test |>
mutate(
log_price_hat = predict(model1, newdata = test),
price_hat = exp(log_price_hat),
price_hat = round(price_hat / 100000) * 100000
) |>
select(property_id, price_hat)
head(predictSample)
model1
write.csv(predictSample,"EN_lambda_0,001_alpha_0,1.csv", row.names = FALSE)
set.seed(2025)
block_folds <- spatial_block_cv(train_sf, v = 5)
library(pacman)
p_load(rio,       # Import/export data.
tidyverse, # Tidy-data.
caret,     # For predictive model assessment.
sf,           # Manejo de datos espaciales.
spatialsample, # Validación cruzada espacial
leaps)     # For subset  model selection
set.seed(2025)
block_folds <- spatial_block_cv(train_sf, v = 5)
train_sf <- st_as_sf(train, coords = c("lon", "lat"), crs = 4326)
block_folds <- spatial_block_cv(train_sf, v = 5)
block_folds <- spatial_block_cv(train, v = 5)
train_sf <- st_as_sf(train, coords = c("lon", "lat"), crs = 4326)
block_folds <- spatial_block_cv(train_sf, v = 5)
train_sf_proj <- st_transform(train_sf, 3116)
block_folds <- spatial_block_cv(train_sf_proj, v = 5)
autoplot(block_folds)
model2 <- train(
espec_modelo,
data = train,
metric = "MAE",
method = "glmnet",
trControl = block_folds,
family = "gaussian",
tuneGrid = expand.grid(
alpha  = seq(0, 1, by= 0.1),
lambda = 10^seq(-3, 3, length = 10)
)
)
`library(reticulate)
reticulate::py_discover_config()`
library(reticulate)
reticulate::py_discover_config()
RETICULATE_PYTHON <- 'C:\Users\catal\Documents\.virtualenvs\r-reticulate\Scripts\python.exe
RETICULATE_PYTHON <- 'C:\Users\catal\Documents\.virtualenvs\r-reticulate\Scripts\python.exe'
RETICULATE_PYTHON <- 'C:\Users\catal\Documents\.virtualenvs\r-reticulate\Scripts\python.exe'
RETICULATE_PYTHON <- "C:\Users\catal\Documents\.virtualenvs\r-reticulate\Scripts\python.exe"
install_keras(envname = "r-reticulate")
RETICULATE_PYTHON <- "C:/Users/catal/Documents/.virtualenvs/r-reticulate/Scripts/python.exe"
reticulate::use_python(RETICULATE_PYTHON, required = TRUE)
library(keras)
install_keras(envname = "r-reticulate")
library(reticulate)
reticulate::py_discover_config()
install.package('tensorflow')
install.packages('tensorflow')
library(tensorflow)
tensorflow::install_tensorflow(envname = 'r-reticulate')
